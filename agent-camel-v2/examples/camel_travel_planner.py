"""
Travel Planner Example using official CAMEL-AI framework.
ä½¿ç”¨å®˜æ–¹CAMEL-AIæ¡†æ¶çš„æ—…è¡Œè§„åˆ’ç¤ºä¾‹
"""
import os
import logging
from typing import Dict, Any, List
from camel.agents import ChatAgent
from camel.messages import BaseMessage
from camel.models import ModelFactory
from camel.types import ModelPlatformType, ModelType, RoleType, OpenAIBackendRole
from camel.configs import ChatGPTConfig
from camel.agents import TaskSpecifyAgent, TaskPlannerAgent
from camel.societies import RolePlaying
from dotenv import load_dotenv

# Load environment variables
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# Define travel roles
# å®šä¹‰æ—…è¡Œè§’è‰²
travel_roles = {
    "travel_planner": {
        "role_name": "TravelPlanner",
        "role_description": "èµ„æ·±æ—…è¡Œè§„åˆ’å¸ˆï¼Œä½ æ˜¯ä¸€ä½æœ‰20å¹´ç»éªŒçš„æ—…è¡Œè§„åˆ’ä¸“å®¶ï¼Œæ“…é•¿æ ¹æ®ç”¨æˆ·åå¥½åˆ¶å®šä¸ªæ€§åŒ–æ—…è¡Œæ–¹æ¡ˆ"
    },
    "local_guide": {
        "role_name": "LocalGuide", 
        "role_description": "å½“åœ°å‘å¯¼ï¼Œä½ æ˜¯ç›®çš„åœ°çš„æœ¬åœ°å±…æ°‘ï¼Œå¯¹å½“åœ°æ–‡åŒ–ã€ç¾é£Ÿå’Œæ™¯ç‚¹äº†å¦‚æŒ‡æŒ"
    },
    "budget_advisor": {
        "role_name": "BudgetAdvisor",
        "role_description": "é¢„ç®—é¡¾é—®ï¼Œä½ æ˜¯è´¢åŠ¡è§„åˆ’ä¸“å®¶ï¼Œæ“…é•¿åœ¨ä¿è¯ä½“éªŒçš„å‰æä¸‹ä¼˜åŒ–æ—…è¡Œå¼€æ”¯"
    }
}

def create_agent(role_type: str, model) -> ChatAgent:
    """
    Create an agent with specified role.
    åˆ›å»ºå…·æœ‰æŒ‡å®šè§’è‰²çš„Agent
    
    Args:
        role_type: Type of role (travel_planner, local_guide, budget_advisor)
               è§’è‰²ç±»å‹
        model: Model to use for the agent
           ç”¨äºAgentçš„æ¨¡å‹
        
    Returns:
        ChatAgent instance
        ChatAgentå®ä¾‹
    """
    print(f"Creating agent with role: {role_type}")
    
    if role_type not in travel_roles:
        logger.warning(f"Unknown role type: {role_type}, defaulting to travel_planner")
        role_type = "travel_planner"
    
    role_info = travel_roles[role_type]
    
    # Create system message (assistant role)
    # åˆ›å»ºç³»ç»Ÿæ¶ˆæ¯ï¼ˆåŠ©æ‰‹è§’è‰²ï¼‰
    assistant_sys_msg = BaseMessage.make_assistant_message(
        role_name=role_info["role_name"],
        content=role_info["role_description"]
    )
    
    # Create the agent
    # åˆ›å»ºAgent
    agent = ChatAgent(
        system_message=assistant_sys_msg,
        model=model,
        token_limit=4096
    )
    
    # Reset the agent
    # é‡ç½®Agent
    agent.reset()
    
    print(f"Agent {role_info['role_name']} created successfully")
    return agent

def camel_travel_planning_conversation(user_request: str) -> Dict[str, Any]:
    """
    Travel planning conversation flow using CAMEL-AI framework with RolePlaying society.
    ä½¿ç”¨CAMEL-AIæ¡†æ¶çš„RolePlayingç¤¾ä¼šè¿›è¡Œæ—…è¡Œè§„åˆ’å¯¹è¯æµç¨‹
    
    Args:
        user_request: User's travel request
                  ç”¨æˆ·çš„æ—…è¡Œè¯·æ±‚
        
    Returns:
        Final travel plan response
        æœ€ç»ˆæ—…è¡Œè®¡åˆ’å“åº”
    """
    print(f"Starting CAMEL RolePlaying travel planning conversation for request: {user_request}")
    
    # Setup model
    # è®¾ç½®æ¨¡å‹
    model_platform = os.getenv("DEFAULT_MODEL_PROVIDER", "openai")
    print(f"Using model platform: {model_platform}")
    
    if model_platform.lower() == "ollama":
        print("Initializing Ollama model")
        model = ModelFactory.create(
            model_platform=ModelPlatformType.OLLAMA,
            model_type=os.getenv("OLLAMA_MODEL_NAME", "llama2"),
            model_config_dict={}
        )
    else:
        # Default to OpenAI
        # é»˜è®¤ä½¿ç”¨OpenAI
        print("Initializing OpenAI model")
        model = ModelFactory.create(
            model_platform=ModelPlatformType.OPENAI,
            model_type=ModelType.GPT_3_5_TURBO,
            model_config_dict=ChatGPTConfig(temperature=0.7, max_tokens=2000).as_dict()
        )
    
    # 1. Use TaskSpecifyAgent to clarify the task
    # 1. ä½¿ç”¨TaskSpecifyAgentæ˜ç¡®ä»»åŠ¡
    print("Creating task specify agent")
    task_specify_agent = TaskSpecifyAgent(model)
    specified_task = task_specify_agent.run(user_request, meta_dict={"domain": "travel planning"})
    print(f"Specified task: {specified_task}")
    
    # 2. Create RolePlaying society for multi-agent collaboration
    # 2. åˆ›å»ºRolePlayingç¤¾ä¼šè¿›è¡Œå¤šæ™ºèƒ½ä½“åä½œ
    print("Creating RolePlaying society")
    
    # Define assistant and user roles for the conversation
    # å®šä¹‰å¯¹è¯ä¸­çš„åŠ©æ‰‹å’Œç”¨æˆ·è§’è‰²
    assistant_role_name = "TravelPlanningExpert"
    user_role_name = "TravelClient"
    
    # Create system messages for both roles
    # ä¸ºä¸¤ä¸ªè§’è‰²åˆ›å»ºç³»ç»Ÿæ¶ˆæ¯
    assistant_sys_msg = BaseMessage.make_assistant_message(
        role_name=assistant_role_name,
        content=(
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…è¡Œè§„åˆ’ä¸“å®¶å›¢é˜Ÿï¼ŒåŒ…å«ä»¥ä¸‹ä¸‰ä¸ªä¸“å®¶ï¼š\n"
            "1. æ—…è¡Œè§„åˆ’å¸ˆï¼šè´Ÿè´£åˆ¶å®šè¯¦ç»†çš„è¡Œç¨‹å®‰æ’å’Œç›®çš„åœ°æ¨è\n"
            "2. å½“åœ°å‘å¯¼ï¼šæä¾›ç›®çš„åœ°çš„æ–‡åŒ–ã€ç¾é£Ÿå’Œæ™¯ç‚¹ä¿¡æ¯\n"
            "3. é¢„ç®—é¡¾é—®ï¼šåˆ¶å®šåˆç†çš„æ—…è¡Œé¢„ç®—å’Œè´¹ç”¨ä¼˜åŒ–å»ºè®®\n"
            "è¯·ä»¥å›¢é˜Ÿåä½œçš„æ–¹å¼ï¼Œä¸ºå®¢æˆ·æä¾›å…¨é¢çš„æ—…è¡Œè§„åˆ’æœåŠ¡ã€‚"
        )
    )
    
    user_sys_msg = BaseMessage.make_user_message(
        role_name=user_role_name,
        content=(
            "ä½ æ˜¯ä¸€ä½å¯»æ±‚ä¸“ä¸šæ—…è¡Œè§„åˆ’æœåŠ¡çš„å®¢æˆ·ã€‚ä½ ä¼šæå‡ºå…·ä½“çš„æ—…è¡Œéœ€æ±‚ï¼Œ"
            "å¹¶ä¸æ—…è¡Œä¸“å®¶å›¢é˜Ÿè¿›è¡Œäº’åŠ¨ï¼Œä»¥è·å¾—æœ€ä½³çš„æ—…è¡Œæ–¹æ¡ˆã€‚"
        )
    )
    
    # Create the RolePlaying society
    # åˆ›å»ºRolePlayingç¤¾ä¼š
    role_play_session = RolePlaying(
        assistant_role_name=assistant_role_name,
        user_role_name=user_role_name,
        assistant_agent_kwargs=dict(
            model=model
        ),
        user_agent_kwargs=dict(
            model=model
        ),
        task_prompt=specified_task,
        with_task_specify=False,  # We already specified the task
        with_task_planner=False,  # We'll handle planning within the conversation
    )
    
    print("Starting RolePlaying conversation")
    
    # Initialize the conversation
    # åˆå§‹åŒ–å¯¹è¯
    input_msg = role_play_session.init_chat()
    
    # Run the conversation for several turns to get comprehensive planning
    # è¿è¡Œå¤šè½®å¯¹è¯ä»¥è·å¾—å…¨é¢çš„è§„åˆ’
    conversation_history = []
    max_turns = 6  # Limit conversation turns
    
    for turn in range(max_turns):
        print(f"Conversation turn {turn + 1}")
        
        # Get assistant response
        # è·å–åŠ©æ‰‹å“åº”
        # Extract messages from ChatAgentResponse objects
        raw_response = role_play_session.step(input_msg)
        assistant_response = raw_response[0]
        user_msg = raw_response[1]

        # Extract the actual message content
        assistant_msg = assistant_response.msgs[0] if hasattr(assistant_response, 'msgs') and assistant_response.msgs else None
        user_message = user_msg.msgs[0] if hasattr(user_msg, 'msgs') and user_msg.msgs else None

        # Update memory with extracted messages
        if hasattr(role_play_session.assistant_agent, 'update_memory') and assistant_msg:
            role_play_session.assistant_agent.update_memory(assistant_msg, OpenAIBackendRole.ASSISTANT)
        if hasattr(role_play_session.user_agent, 'update_memory') and user_message:
            role_play_session.user_agent.update_memory(user_message, OpenAIBackendRole.USER)
        
        if assistant_response.terminated:
            print("Conversation terminated by assistant")
            break
            
        conversation_history.append({
            "turn": turn + 1,
            "assistant": assistant_msg.content if assistant_msg else "",
            "user": user_message.content if user_message else ""
        })
        
        # Use the extracted user message as input for next turn
        # ä½¿ç”¨æå–çš„ç”¨æˆ·æ¶ˆæ¯ä½œä¸ºä¸‹ä¸€è½®çš„è¾“å…¥
        input_msg = user_message
        
        # Break if user message indicates completion
        # å¦‚æœç”¨æˆ·æ¶ˆæ¯è¡¨ç¤ºå®Œæˆåˆ™ä¸­æ–­
        if user_message and ("å®Œæˆ" in user_message.content or "æ»¡æ„" in user_message.content or "è°¢è°¢" in user_message.content):
            print("Conversation completed by user satisfaction")
            break
    
    # Extract the final comprehensive response
    # æå–æœ€ç»ˆçš„ç»¼åˆå“åº”
    if conversation_history:
        final_response = conversation_history[-1]["assistant"]
    else:
        final_response = "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆæ—…è¡Œè§„åˆ’ã€‚è¯·ç¨åé‡è¯•ã€‚"
    
    print("CAMEL RolePlaying travel planning conversation completed")
    return {
        "response": final_response,
        "conversation_history": conversation_history,
        "status": "success"
    }

def synthesize_results(results: Dict[str, str], user_request: str) -> str:
    """
    Synthesize results from multiple agents into a final response.
    å°†å¤šä¸ªAgentsçš„ç»“æœç»¼åˆæˆæœ€ç»ˆå“åº”
    
    Args:
        results: Results from different agents
             æ¥è‡ªä¸åŒAgentsçš„ç»“æœ
        user_request: Original user request
                  åŸå§‹ç”¨æˆ·è¯·æ±‚
        
    Returns:
        Final synthesized response
        æœ€ç»ˆç»¼åˆå“åº”
    """
    print("Synthesizing results from multiple agents")
    
    # Create a summary of all agent responses
    # åˆ›å»ºæ‰€æœ‰Agentå“åº”çš„æ‘˜è¦
    response_text = f"æ ¹æ®æ‚¨çš„è¯·æ±‚ '{user_request}'ï¼Œæˆ‘ä»¬ä¸ºæ‚¨æä¾›ä»¥ä¸‹æ—…è¡Œå»ºè®®ï¼š\n\n"
    
    response_text += "ğŸŒ ç›®çš„åœ°è§„åˆ’ï¼š\n"
    response_text += f"{results.get('destination_planning', 'æ­£åœ¨ä¸ºæ‚¨è§„åˆ’æœ€ä½³ç›®çš„åœ°...')}\n\n"
    
    response_text += "ğŸ“ å½“åœ°æŒ‡å—ï¼š\n"
    response_text += f"{results.get('local_guidance', 'æ­£åœ¨ä¸ºæ‚¨æ”¶é›†å½“åœ°ä¿¡æ¯...')}\n\n"
    
    response_text += "ğŸ’° é¢„ç®—è§„åˆ’ï¼š\n"
    response_text += f"{results.get('budget_planning', 'æ­£åœ¨ä¸ºæ‚¨åˆ¶å®šé¢„ç®—è®¡åˆ’...')}\n\n"
    
    print("Results synthesized successfully")
    return response_text

def execute_agent_task(agent: ChatAgent, task_description: str) -> str:
    """
    Execute a task with the given agent.
    ä½¿ç”¨ç»™å®šAgentæ‰§è¡Œä»»åŠ¡
    
    Args:
        agent: ChatAgent to execute the task
           æ‰§è¡Œä»»åŠ¡çš„ChatAgent
        task_description: Description of the task
                    ä»»åŠ¡æè¿°
        
    Returns:
        Task execution result
        ä»»åŠ¡æ‰§è¡Œç»“æœ
    """
    print(f"Executing task with agent {agent.role_name}")
    
    # Create user message
    # åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
    user_msg = BaseMessage.make_user_message(
        role_name="User",
        content=task_description
    )
    
    # Get response from agent
    # ä»Agentè·å–å“åº”
    print(f"Sending task to agent {agent.role_name}: {task_description}")
    response = agent.step(user_msg)
    print(f"Received response from agent {agent.role_name}")
    
    if response.msgs:
        result_content = response.msgs[0].content
        print(f"Task executed successfully by agent {agent.role_name} with result: {result_content}")
        return result_content
    else:
        logger.warning(f"Failed to execute task with agent {agent.role_name}")
        return f"æŠ±æ­‰ï¼Œ{agent.role_name}æ— æ³•ç”Ÿæˆå“åº”ï¼Œè¯·ç¨åé‡è¯•ã€‚"

def main():
    """Main function to run the CAMEL-AI travel planner.
    è¿è¡ŒCAMEL-AIæ—…è¡Œè§„åˆ’å™¨çš„ä¸»å‡½æ•°"""
    print("Starting CAMEL-AI Multi-Role Travel Planner")
    print("CAMEL-AI Multi-Role Travel Planner")
    print("=" * 40)
    
    # Get user input
    # è·å–ç”¨æˆ·è¾“å…¥
    user_request = input("è¯·è¾“å…¥æ‚¨çš„æ—…è¡Œéœ€æ±‚: ")
    print(f"User input received: {user_request}")
    
    if not user_request.strip():
        logger.warning("No valid travel request provided")
        print("æœªæä¾›æœ‰æ•ˆçš„æ—…è¡Œéœ€æ±‚ã€‚")
        return
    
    print(f"\næ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚: {user_request}")
    print("è¯·ç¨å€™...")
    print(f"Processing user request: {user_request}")
    
    # Process the travel request
    # å¤„ç†æ—…è¡Œè¯·æ±‚
    result = camel_travel_planning_conversation(user_request)
    print("Travel request processing completed")
    
    # Display the result
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 50)
    print("æ—…è¡Œè®¡åˆ’ç»“æœ:")
    print("=" * 50)
    print(result["response"])
    
    # Display detailed results if in debug mode
    # å¦‚æœå¤„äºè°ƒè¯•æ¨¡å¼åˆ™æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    if logger.isEnabledFor(logging.DEBUG):
        print("\nè¯¦ç»†ä¿¡æ¯:")
        for key, value in result["details"].items():
            print(f"- {key}: {value}")
    
    print("Displayed travel plan result to user")


if __name__ == "__main__":
    main()