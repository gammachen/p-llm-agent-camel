# Agent-Camel V2

基于官方 CAMEL-AI 框架的多智能体协作系统，专注于通过角色扮演和对话促进大语言模型的心智探索与任务协作。本项目针对复杂任务（如旅行规划）实现了智能体间的高效协同工作。

## 项目结构

```
agent-camel-v2/
├── README.md
├── requirements.txt
├── .env
├── main.py
├── config/
│   ├── __init__.py
│   └── settings.py
├── agents/
│   ├── __init__.py
│   ├── base.py
│   ├── coordinator.py
│   ├── model_provider.py
│   └── roles/
├── tools/
│   ├── __init__.py
│   └── library.py
├── memory/
│   ├── __init__.py
│   └── manager.py
└── examples/
    ├── __init__.py
    ├── travel_planner.py
    └── camel_travel_planner.py
```

## 安装依赖

```bash
pip install -r requirements.txt
```

## 环境配置

项目使用 `.env` 文件来管理环境变量。请根据需要修改 `.env` 文件中的配置项：

```env
# OpenAI Configuration
OPENAI_API_KEY=sk-...               # 你的OpenAI API密钥
OPENAI_BASE_URL=                    # 可选，OpenAI API的基础URL（用于代理或本地部署）

# Ollama Configuration (for local deployment)
OLLAMA_BASE_URL=http://localhost:11434  # Ollama服务地址
OLLAMA_MODEL_NAME=llama2            # Ollama模型名称

# Comet ML Monitoring Configuration
COMET_API_KEY=your_comet_api_key    # 你的Comet ML API密钥
COMET_PROJECT_NAME=your_project_name  # Comet ML项目名称
COMET_WORKSPACE=your_workspace_name  # Comet ML工作区名称
COMET_LOG_MODEL_CALLS=true          # 是否记录模型调用 (true/false)

# 其他配置...
```

### 使用本地Ollama模型

要使用本地部署的Ollama模型，请确保：

1. 已安装并运行Ollama服务
2. 在 `.env` 文件中配置 `OLLAMA_BASE_URL`（默认为 http://localhost:11434）
3. 拉取所需的模型，例如：`ollama pull llama2`

### 使用OpenAI兼容API

如果使用与OpenAI兼容的API（如本地部署的模型服务），可以通过设置 `OPENAI_BASE_URL` 来配置：

```env
OPENAI_API_KEY=sk-...               # API密钥（如果需要）
OPENAI_BASE_URL=http://localhost:8000/v1  # API服务地址
```

## 运行应用

```bash
# 交互式运行
python main.py

# 直接传入参数运行
python main.py "我想在10月去日本旅行，预算5000美元"
```

## 项目组件说明

本项目基于官方的 [CAMEL-AI](https://github.com/camel-ai/camel) 框架构建，充分利用其先进的多智能体协作机制和角色扮演能力。以下是项目各核心组件的详细说明：

### 配置模块 (config/)
负责加载和管理应用配置，包括API密钥、模型设置和环境变量。配置模块确保应用可以无缝切换不同的模型服务提供商。

### 智能体模块 (agents/)
项目的核心组件，实现智能体的创建、管理和协作：
- `base.py`: 定义了智能体的基础接口和通用功能，所有智能体类型的抽象基类
- `coordinator.py`: 实现了智能体间的任务分配、协调和通信机制，是多智能体系统的"大脑"
- `model_provider.py`: 提供统一的模型访问接口，支持动态切换不同模型服务（OpenAI、Ollama等）
- `comet_monitor.py`: 实现了与Comet ML的集成，用于监控和记录模型调用信息
- `roles/`: 包含各种角色定义，每个角色有特定的能力和行为模式

### 工具模块 (tools/)
为智能体提供外部功能扩展：
- `library.py`: 实现了各种工具函数，使智能体能够执行特定任务（如信息检索、数据分析等）

### 内存模块 (memory/)
实现了会话历史和上下文的管理：
- `manager.py`: 负责存储、检索和更新智能体的记忆，支持长期和短期记忆管理

### 示例模块 (examples/)
包含基于CAMEL-AI框架的应用实现示例：
- `travel_planner.py`: 基础旅行规划助手实现
- `camel_travel_planner.py`: 高级旅行规划实现，充分利用CAMEL-AI的角色扮演和多智能体协作能力

## 支持的模型服务

1. **OpenAI**: 支持GPT-3.5、GPT-4等模型
2. **Ollama**: 支持本地部署的大模型（如Llama系列）

通过配置环境变量，可以轻松切换不同的模型服务提供商。

## 应用流程详解

### 旅行规划助手实现流程

`camel_travel_planner.py`是本项目的核心示例实现，展示了如何利用CAMEL-AI框架构建一个功能完整的旅行规划多智能体系统。以下是其详细工作流程：

1. **初始化阶段**
   - 加载配置并设置模型服务
   - 创建角色定义（旅行规划专家和用户）
   - 初始化RolePlaying会话和记忆系统
   - 配置智能体参数（模型类型、系统提示等）

2. **角色交互循环**
   - 用户输入旅行需求（目的地、日期、预算等）
   - 系统将需求传递给旅行规划专家智能体
   - 旅行规划专家生成初步建议或询问更多细节
   - 用户智能体基于专家回复生成进一步的问题或确认
   - 系统记录对话历史并更新记忆
   - 循环继续直到用户表示满意或完成规划

3. **记忆更新机制**
   - 每次对话回合后提取关键信息
   - 将信息以BaseMessage格式存储到记忆系统
   - 使用OpenAIBackendRole标识不同发言者的角色
   - 确保记忆系统中的消息格式符合验证要求

4. **会话终止条件**
   - 当用户消息中包含"完成"、"满意"或"谢谢"等关键词时终止对话
   - 生成最终的旅行规划方案并返回给用户

## CAMEL-AI 框架能力与应用

本项目充分利用了CAMEL-AI框架的核心能力，实现了高效的智能体协作系统。以下是框架关键能力及其在项目中的应用：

### 1. 多智能体协作机制

CAMEL-AI框架实现了先进的智能体间通信和协作机制，项目通过以下方式利用这一能力：
- **智能体角色分配**: 根据任务需求为智能体分配特定角色（如旅行顾问、行程规划师等）
- **回合制对话系统**: 实现智能体间有序的信息交换和决策过程
- **任务导向协作**: 确保所有智能体围绕共同目标协同工作

### 2. 角色扮演实现

角色扮演是CAMEL-AI框架的核心特性，项目通过以下方式实现：
- **角色定义**: 为每个智能体设定详细的角色描述、能力边界和行为准则
- **系统提示优化**: 精心设计系统提示以引导智能体表现出符合角色的行为
- **角色互动约束**: 确保智能体在对话中保持角色一致性

### 3. 任务分解与分配

针对复杂任务（如旅行规划），项目实现了以下策略：
- **分层任务分解**: 将复杂任务拆分为多个子任务（如目的地选择、行程安排、预算规划等）
- **能力匹配**: 根据智能体的特长分配合适的子任务
- **进度协调**: 监控各子任务进展并协调整体任务完成

### 4. 记忆管理系统

项目实现了高效的记忆管理机制，支持智能体在长期对话中保持上下文一致性：
- **会话历史存储**: 记录智能体间的完整对话历史
- **关键信息提取**: 从对话中提取重要实体和决策信息
- **上下文维护**: 在对话过程中动态更新和维护上下文信息

## 技术实现与修复的问题

在项目实现过程中，我们解决了以下关键技术问题：

1. **参数冲突问题**: 修复了在RolePlaying初始化过程中系统消息参数重复传递的问题
   - 解决方案: 移除了agent_kwargs中显式声明的system_message参数，避免与RolePlaying内部处理冲突

2. **消息处理机制**: 解决了ChatAgentResponse对象属性访问错误
   - 解决方案: 正确使用.msgs[0].content访问消息内容，并添加了空值检查

3. **记忆记录验证**: 修复了MemoryRecord验证错误
   - 解决方案: 确保向记忆系统传递正确类型的消息对象（BaseMessage实例），通过提取ChatAgentResponse中的msgs[0]属性

4. **类型导入完善**: 添加了缺失的OpenAIBackendRole导入，确保类型引用的完整性

5. **代码一致性优化**: 统一了对话循环中的消息处理逻辑，确保各部分代码使用相同的消息提取方式，提高了代码的可维护性

## CAMEL-AI框架高级特性

### 模型适配性

CAMEL-AI框架设计具有高度的模型适配性：
- 支持多种大语言模型平台（OpenAI、Ollama等）
- 提供统一的接口抽象，使切换模型变得简单
- 自适应不同模型的特性和限制

### 扩展性设计

框架具有良好的扩展性，支持：
- 自定义智能体角色和行为
- 集成外部工具和API
- 扩展记忆管理机制
- 实现自定义的会话流程控制

### 性能优化

框架内置了多种性能优化机制：
- 对话上下文压缩
- 记忆选择性存储
- 智能缓存机制
- 资源使用监控

## 最佳实践与开发建议

1. **角色设计建议**
   - 为智能体提供清晰、具体的角色定义
   - 明确每个角色的职责和能力边界
   - 设计互补的角色组合以提高任务完成效率

2. **系统提示优化**
   - 精心设计系统提示以引导智能体行为
   - 使用结构化的提示模板提高一致性
   - 避免模糊表述，确保指令明确

3. **错误处理策略**
   - 实现健壮的错误捕获和恢复机制
   - 为关键操作添加重试逻辑
   - 设计优雅的失败处理流程

## 总结

本项目成功实现了基于CAMEL-AI框架的多智能体协作系统，特别针对旅行规划场景进行了优化。通过解决关键技术问题，完善了智能体交互机制，实现了高效的角色扮演和任务协作。项目充分展示了CAMEL-AI框架在构建复杂多智能体应用方面的强大能力，为进一步开发更高级的智能体系统奠定了基础。